
# Automated Test Script For GTA-V

#### Importing required libraries


```python
import numpy as np
import pandas as pd
import sys, os

import warnings
warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)
```

#### Locating our logs files in our working directory


```python
LOGS_PATH = os.path.join(os.getcwd(), 'logs')
```

#### Replace this with the log file name that your looking to test


```python
LOG_BARCODE = '2018-04-07_18-35'
```

#### Loading DeepEye & Tester log files into Pandas DataFrames


```python
tester_log = pd.read_csv(os.path.join(LOGS_PATH, "[" + LOG_BARCODE + "]--DeepEye.csv"), index_col=0)
deepeye_log = pd.read_csv(os.path.join(LOGS_PATH, "[" + LOG_BARCODE + "]--Tester.csv"), index_col=0) 
```

## Compare the two dataframes and identify each feature where the `GROUND TRUTH` and the `PREDICTION` by DeepEye were different


```python
results = pd.concat([tester_log.set_index('FRAME_ID'), deepeye_log.set_index('FRAME_ID')], 
                   axis='columns', keys=['GROUND TRUTH', 'PREDICTION'])

results = results.swaplevel(axis='columns')[tester_log.columns[1:]]
results.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">PEDESTRIAN</th>
      <th colspan="2" halign="left">VEHICLES</th>
      <th colspan="2" halign="left">BIKES</th>
      <th colspan="2" halign="left">STOP_SIGN</th>
      <th colspan="2" halign="left">TRAFFIC_LIGHT</th>
      <th colspan="2" halign="left">OFF_LANE</th>
      <th colspan="2" halign="left">COLLISION</th>
    </tr>
    <tr>
      <th></th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
    </tr>
    <tr>
      <th>FRAME_ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



#### Look at False Positive/Negative Predictions


```python
log = (tester_log != deepeye_log).stack()
df = log[log]
df.index.names = ['FRAME_ID', 'FEATURE']
difference_loc = np.where(tester_log != deepeye_log)
ground_truth = tester_log.values[difference_loc]
prediction = deepeye_log.values[difference_loc]
wrong_predictions = pd.DataFrame({'GROUND TRUTH': ground_truth, 'PREDICTION': prediction}, index=df.index)
```


```python
wrong_predictions.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
    </tr>
    <tr>
      <th>FRAME_ID</th>
      <th>FEATURE</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">1</th>
      <th>PEDESTRIAN</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>TRAFFIC_LIGHT</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">3</th>
      <th>TRAFFIC_LIGHT</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>COLLISION</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <th>VEHICLES</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



### Calculate a score for each frame based on the number of false predictions


```python
scores = wrong_predictions.groupby(['FRAME_ID']).size().reset_index(name='SCORE')
scores =  len(tester_log.columns) - scores['SCORE'] - 1

results['ACCURACY', 'SCORE'] = scores
results['ACCURACY', 'SCORE'].fillna(len(tester_log.columns) - 1, inplace=True) 
results['ACCURACY', 'SCORE'] = results['ACCURACY', 'SCORE'] / 7
results.style.format("{:.2%}", subset=pd.IndexSlice[:, pd.IndexSlice[:, 'SCORE']])

results.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">PEDESTRIAN</th>
      <th colspan="2" halign="left">VEHICLES</th>
      <th colspan="2" halign="left">BIKES</th>
      <th colspan="2" halign="left">STOP_SIGN</th>
      <th colspan="2" halign="left">TRAFFIC_LIGHT</th>
      <th colspan="2" halign="left">OFF_LANE</th>
      <th colspan="2" halign="left">COLLISION</th>
      <th>ACCURACY</th>
    </tr>
    <tr>
      <th></th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>GROUND TRUTH</th>
      <th>PREDICTION</th>
      <th>SCORE</th>
    </tr>
    <tr>
      <th>FRAME_ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.714286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.714286</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.714286</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.857143</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.714286</td>
    </tr>
  </tbody>
</table>
</div>



## Display some basic statistical analytics

### Overall Performance


```python
pd.DataFrame(results['ACCURACY', 'SCORE'].describe())
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>ACCURACY</th>
    </tr>
    <tr>
      <th></th>
      <th>SCORE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>442.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.874596</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.114521</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.428571</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.857143</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.857143</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



### Filter out the wrong predictions from the table to calculate the weighted average of our accurate prediction


```python
log = (tester_log == deepeye_log).stack()
df = log[log]
df.index.names = ['FRAME_ID', 'FEATURE']
right_predictions = pd.DataFrame(df, index=df.index)
```

### Total of correct predictions by feature


```python
right_predictions = right_predictions.groupby(['FEATURE']).size().reset_index(name='COUNT')
right_predictions
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FEATURE</th>
      <th>COUNT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>FRAME_ID</td>
      <td>442</td>
    </tr>
    <tr>
      <th>1</th>
      <td>PEDESTRIAN</td>
      <td>366</td>
    </tr>
    <tr>
      <th>2</th>
      <td>VEHICLES</td>
      <td>311</td>
    </tr>
    <tr>
      <th>3</th>
      <td>BIKES</td>
      <td>432</td>
    </tr>
    <tr>
      <th>4</th>
      <td>STOP_SIGN</td>
      <td>432</td>
    </tr>
    <tr>
      <th>5</th>
      <td>TRAFFIC_LIGHT</td>
      <td>293</td>
    </tr>
    <tr>
      <th>6</th>
      <td>OFF_LANE</td>
      <td>442</td>
    </tr>
    <tr>
      <th>7</th>
      <td>COLLISION</td>
      <td>430</td>
    </tr>
  </tbody>
</table>
</div>



### Predictions results for Pedstrians


```python
target = results.groupby(results['PEDESTRIAN', 'PREDICTION'], axis=0).describe()
target['ACCURACY', 'SCORE']
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>(PEDESTRIAN, PREDICTION)</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>329.0</td>
      <td>0.888406</td>
      <td>0.113828</td>
      <td>0.428571</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.000000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>113.0</td>
      <td>0.834387</td>
      <td>0.107256</td>
      <td>0.571429</td>
      <td>0.714286</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
tp = int(right_predictions[right_predictions['FEATURE'] == 'PEDESTRIAN']['COUNT'])
total = int(right_predictions[right_predictions['FEATURE'] == 'FRAME_ID']['COUNT'])
print('Accuracy: ', tp / total)
```

    Accuracy:  0.8280542986425339


### Predictions results for Vehicles


```python
target = results.groupby(results['VEHICLES', 'PREDICTION'], axis=0).describe()
target['ACCURACY', 'SCORE']
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>(VEHICLES, PREDICTION)</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>48.0</td>
      <td>0.934524</td>
      <td>0.097553</td>
      <td>0.714286</td>
      <td>0.857143</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>394.0</td>
      <td>0.867295</td>
      <td>0.114397</td>
      <td>0.428571</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
tp = int(right_predictions[right_predictions['FEATURE'] == 'VEHICLES']['COUNT'])
total = int(right_predictions[right_predictions['FEATURE'] == 'FRAME_ID']['COUNT'])
print('Accuracy: ', tp / total)
```

    Accuracy:  0.7036199095022625


### Predictions results for Bikes


```python
target = results.groupby(results['BIKES', 'PREDICTION'], axis=0).describe()
target['ACCURACY', 'SCORE']
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>(BIKES, PREDICTION)</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>433.0</td>
      <td>0.875289</td>
      <td>0.114602</td>
      <td>0.428571</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.000000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.0</td>
      <td>0.841270</td>
      <td>0.111677</td>
      <td>0.571429</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
tp = int(right_predictions[right_predictions['FEATURE'] == 'BIKES']['COUNT'])
total = int(right_predictions[right_predictions['FEATURE'] == 'FRAME_ID']['COUNT'])
print('Accuracy: ', tp / total)
```

    Accuracy:  0.9773755656108597


### Predictions results for Stop Signs


```python
target = results.groupby(results['STOP_SIGN', 'PREDICTION'], axis=0).describe()
target['ACCURACY', 'SCORE']
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>(STOP_SIGN, PREDICTION)</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>430.0</td>
      <td>0.875748</td>
      <td>0.115146</td>
      <td>0.428571</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.000000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12.0</td>
      <td>0.833333</td>
      <td>0.082479</td>
      <td>0.714286</td>
      <td>0.821429</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
tp = int(right_predictions[right_predictions['FEATURE'] == 'STOP_SIGN']['COUNT'])
total = int(right_predictions[right_predictions['FEATURE'] == 'FRAME_ID']['COUNT'])
print('Accuracy: ', tp / total)
```

    Accuracy:  0.9773755656108597


### Predictions results for Traffic Lights


```python
target = results.groupby(results['TRAFFIC_LIGHT', 'PREDICTION'], axis=0).describe()
target['ACCURACY', 'SCORE']
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>(TRAFFIC_LIGHT, PREDICTION)</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>259.0</td>
      <td>0.899062</td>
      <td>0.115175</td>
      <td>0.428571</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.000000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>183.0</td>
      <td>0.839969</td>
      <td>0.104483</td>
      <td>0.571429</td>
      <td>0.714286</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
tp = int(right_predictions[right_predictions['FEATURE'] == 'TRAFFIC_LIGHT']['COUNT'])
total = int(right_predictions[right_predictions['FEATURE'] == 'FRAME_ID']['COUNT'])
print('Accuracy: ', tp / total)
```

    Accuracy:  0.6628959276018099


### Predictions results for Off-Lane Warnings


```python
target = results.groupby(results['OFF_LANE', 'PREDICTION'], axis=0).describe()
target['ACCURACY', 'SCORE']
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>(OFF_LANE, PREDICTION)</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>442.0</td>
      <td>0.874596</td>
      <td>0.114521</td>
      <td>0.428571</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
tp = int(right_predictions[right_predictions['FEATURE'] == 'OFF_LANE']['COUNT'])
total = int(right_predictions[right_predictions['FEATURE'] == 'FRAME_ID']['COUNT'])
print('Accuracy: ', tp / total)
```

    Accuracy:  1.0


### Predictions results for Collision Warnings


```python
target = results.groupby(results['COLLISION', 'PREDICTION'], axis=0).describe()
target['ACCURACY', 'SCORE']
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>(COLLISION, PREDICTION)</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>428.0</td>
      <td>0.874833</td>
      <td>0.115359</td>
      <td>0.428571</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.000000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14.0</td>
      <td>0.867347</td>
      <td>0.087961</td>
      <td>0.714286</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
tp = int(right_predictions[right_predictions['FEATURE'] == 'COLLISION']['COUNT'])
total = int(right_predictions[right_predictions['FEATURE'] == 'FRAME_ID']['COUNT'])
print('Accuracy: ', tp / total)
```

    Accuracy:  0.9728506787330317

