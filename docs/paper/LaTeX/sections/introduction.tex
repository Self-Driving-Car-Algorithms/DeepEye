\chapter{Introduction}
% (2-3 pages)

\section{Problem Statement} 
%-------------------------------------------%

Our project aims to successfully build, then evaluate a vision-based scene recognition model that classifies relevant objects surrounding a driving agent, and accurately estimates whether the driver is staying in lane or not. The system would analyze the scene, then alert the driver if any of the objects pose a potential threat through the dashboard.

%-------------------------------------------%



\section{Purpose Statement} 
%-------------------------------------------%

This project will demonstrate how a vision-based system can be utilized for scene understanding when sensor-based systems are not available for autonomous driving.

%-------------------------------------------%



\section{Context} 
%-------------------------------------------%

Ever since the concept of autonomous vehicles was introduced to the IT industry as an application of artificial intelligence, there have been tremendous improvements in computer vision and pattern recognition algorithms. However, recent progress in autonomous models has been extensively criticized by many experts in various disciplines for being too expensive, due to the time and the cost associated with human labor to collect massive training datasets, not to mention the complexity of such systems. Fortunately, video games are utilized to reduce the cost of collecting large training datasets, as well as providing a decent simulated environment to test models in their early stages. Surprisingly enough, some of the statistical reports show that supplementing a small percentage of real-world data with massive datasets acquired from video games would significantly improve an agentâ€™s performance. 

In the last five years, manufacturers have demonstrated the potential of autonomous cars on highways. However, navigating noisy urban areas remains an unsolved problem. This is mainly due to the complexity of scenario-based scene recognition, and 3D traffic scene understanding. One of the solutions is to rely on GPS localization systems and advanced on-board sensors to create 3D maps of the environment. However, constructing accurate maps is nearly impossible in practice. Also, GPS signals are not always available, and the system would potentially fail in underground areas like tunnels, and in severe weather conditions.  There are also many ethical and security issues that exist with current models. Hence, a combination of vision-based models in addition to sensory-based systems would certainly help to overcome many of the current challenges. 

%-------------------------------------------%



\section{Significance of Project} 
%-------------------------------------------%

Autonomous vehicle engineering appears to be a dominant industry in the future of information technology and artificial intelligence.  Demonstrating how an autonomous agent can learn in an efficient, safe, and pragmatic virtual environment will have tremendous potential to revolutionize machine learning algorithms and computer-vision methodologies. Our project is mainly focused on real scene layout recognition through computer vision that would ultimately make use of advanced sensors (i.e. LIDAR) if the models were to be used for `real-world' applications. However, our work will also train and test vision-based models for an autonomous copilot system without sensory inputs. We will provide several statistical evidences to demonstrate the performance of the system and its potential to generalize its learned model to real life driving environments. 
 
%-------------------------------------------%
